{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taxi.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarK-ML/Taxi/blob/master/Taxi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHpgnnNy301I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import gym"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wukqlEk35or",
        "colab_type": "code",
        "outputId": "57281144-9fb0-40e1-c73e-83dae8f36cfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "env = gym.make(\"Taxi-v3\") # Create environment\n",
        "env.render() # Show it"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| :\u001b[43m \u001b[0m| : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[34;1mY\u001b[0m| : |\u001b[35mB\u001b[0m: |\n",
            "+---------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABWn3BMF37Hd",
        "colab_type": "code",
        "outputId": "a84bbb20-50a5-4b3b-b15f-bd2d679033c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Number of possible actions\n",
        "action_size = env.action_space.n \n",
        "print(\"Action size \", action_size) \n",
        "\n",
        "# Number of possible states\n",
        "state_size = env.observation_space.n \n",
        "print(\"State size \", state_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action size  6\n",
            "State size  500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB2GlHvW38ck",
        "colab_type": "code",
        "outputId": "7525831d-9fff-46e8-c05b-de08c43aef93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "qtable = np.zeros((state_size, action_size))\n",
        "print(qtable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgXpNfFc3-JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "episodes = 30000            # Total episodes\n",
        "max_steps = 1000            # Max steps per episode\n",
        "lr = 0.3                    # Learning rate\n",
        "decay_fac = 0.00001         # Decay learning rate each iteration\n",
        "gamma = 0.90                # Discounting rate - later rewards impact less"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7QDnslu3_nS",
        "colab_type": "code",
        "outputId": "fe5ddfc9-9b6c-46a7-c83e-b54adf5ed483",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "for episode in range(episodes):\n",
        "    \n",
        "    state = env.reset() # Reset the environment\n",
        "    done = False        # Are we done with the environment\n",
        "    lr -= decay_fac     # Decaying learning rate\n",
        "    step = 0\n",
        "    \n",
        "    if lr <= 0: # Nothing more to learn?\n",
        "        break\n",
        "        \n",
        "    for step in range(max_steps):\n",
        "        \n",
        "        # Randomly Choose an Action\n",
        "        action = env.action_space.sample()\n",
        "        \n",
        "        # Take the action -> observe new state and reward\n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        # Update qtable values\n",
        "        if done == True: # If last, do not count future accumulated reward\n",
        "            if(step < 199 | step > 201):\n",
        "                qtable[state, action] = qtable[state, action]+lr*(reward+gamma*0-qtable[state,action])\n",
        "            break\n",
        "        else: # Consider accumulated reward of best decision stream\n",
        "            qtable[state, action] = qtable[state,action]+lr*(reward+gamma*np.max(qtable[new_state,:])-qtable[state,action])\n",
        "    \n",
        "        # if done.. jump to next episode\n",
        "        if done == True:\n",
        "            break\n",
        "        \n",
        "        # moving states\n",
        "        state = new_state\n",
        "        \n",
        "    episode += 1\n",
        "    \n",
        "    if (episode % 3000 == 0):\n",
        "        print('episode = ', episode)\n",
        "        print('learning rate = ', lr)\n",
        "        print('-----------')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode =  3000\n",
            "learning rate =  0.26999999999997\n",
            "-----------\n",
            "episode =  6000\n",
            "learning rate =  0.23999999999993998\n",
            "-----------\n",
            "episode =  9000\n",
            "learning rate =  0.20999999999990998\n",
            "-----------\n",
            "episode =  12000\n",
            "learning rate =  0.17999999999987998\n",
            "-----------\n",
            "episode =  15000\n",
            "learning rate =  0.14999999999984998\n",
            "-----------\n",
            "episode =  18000\n",
            "learning rate =  0.11999999999982693\n",
            "-----------\n",
            "episode =  21000\n",
            "learning rate =  0.08999999999983856\n",
            "-----------\n",
            "episode =  24000\n",
            "learning rate =  0.059999999999848445\n",
            "-----------\n",
            "episode =  27000\n",
            "learning rate =  0.029999999999839697\n",
            "-----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlyLccTt4BEU",
        "colab_type": "code",
        "outputId": "1627c9c5-a771-4cc8-8fcf-638d3f0dfe20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# New environment\n",
        "state = env.reset()\n",
        "env.render()\n",
        "done = False\n",
        "total_reward = 0\n",
        "\n",
        "while(done == False):\n",
        "    \n",
        "    action = np.argmax(qtable[state,:]) # Choose best action (Q-table)\n",
        "    state, reward, done, info = env.step(action) # Take action\n",
        "    total_reward += reward  # Summing rewards\n",
        "    \n",
        "    # Display it\n",
        "    time.sleep(0.5)\n",
        "    clear_output(wait=True)\n",
        "    env.render()\n",
        "    print('Episode Reward = ', total_reward)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+\n",
            "|R: | : :G|\n",
            "| : | : : |\n",
            "| : : : : |\n",
            "| | : | : |\n",
            "|\u001b[35m\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m\u001b[0m| : |B: |\n",
            "+---------+\n",
            "  (Dropoff)\n",
            "Episode Reward =  10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLUo21N-4DD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}